{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<p>\n",
    "<a href=\"https://colab.research.google.com/github/tuftsdatalab/pybc/blob/master/pybc-python-data-analysis/pybc-python-data-analysis.ipynb\" target=\"_blank\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<a href=\"https://cdn.jsdelivr.net/gh/tuftsdatalab/pybc/pybc-python-data-analysis/pybc-python-data-analysis.ipynb\" target=\"_blank\">\n",
    "    <img src=\"https://tuftsdatalab.github.io/assets/badges/jupyter.svg\" alt=\"Download Notebook\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<a href=\"https://github.com/tuftsdatalab/pybc\" target=\"_blank\">\n",
    "    <img src=\"https://tuftsdatalab.github.io/assets/badges/github.svg\" alt=\"View on GitHub\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<a href=\"https://github.com/tuftsdatalab/pybc/archive/master.zip\" target=\"_blank\">\n",
    "    <img src=\"https://tuftsdatalab.github.io/assets/badges/download.svg\" alt=\"Download Zip\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<span><img src=\"https://img.shields.io/github/repo-size/tuftsdatalab/pybc?label=total%20size\" alt=\"total size\" style=\"float: left;\"/></span>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<span><img src=\"https://img.shields.io/github/last-commit/tuftsdatalab/pybc?label=last%20updated\" alt=\"last updated\" style=\"float: left;\"/></span>\n",
    "</p>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Boot Camp: Python for Data Analysis and Visualization\n",
    "\n",
    "---\n",
    "**A Tufts University Data Lab Wokrshop**\\\n",
    "Written by Uku-Kaspar Uustalu\n",
    "\n",
    "<html>\n",
    "<p>\n",
    "<a href=\"https://sites.tufts.edu/datalab/\" target=\"_blank\">\n",
    "        <img src=\"https://tuftsdatalab.github.io/assets/badges/datalab.svg\" alt=\"datalab.tufts.edu\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<a href=\"https://twitter.com/intent/follow?screen_name=tuftsdatalab\" target=\"_blank\">\n",
    "        <img src=\"https://tuftsdatalab.github.io/assets/badges/twitter.svg\" alt=\"@TuftsDataLab\" style=\"float: left;\"/></a>\n",
    "<br>\n",
    "</p>\n",
    "</html>\n",
    "\n",
    "Python resoucres: [go.tufts.edu/python](https://sites.tufts.edu/datalab/python/)\\\n",
    "Questions: [datalab-support@elist.tufts.edu](mailto:datalab-support@elist.tufts.edu)\\\n",
    "Feedback: [uku-kaspar.uustalu@tufts.edu](mailto:uku-kaspar.uustalu@tufts.edu)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab Setup\n",
    "If you are using Google Colab, please do the following **before proceeding**:\n",
    "1. If you are not already signed into your Google account, click on *Sign In* in the upper-right corner and sign in with your Google credentials. You must be signed in with a Google account to be able to run notebooks in Google Colab.\n",
    "2. Save a copy of the notebook to your Google Drive by clicking the *Copy to Drive* button above or selecting *File > Save a copy in Drive*. A copy of this notebook saved to your Google Drive will pop up. Close the original file and use the copy for the rest of the workshop. Now any changes you make will be saved to your Google Drive. Feel free to rename the copy if desired. You can still run the notebook without saving it to your Google Drive, but your progress and any changes you make will not be retained when you close the notebook.\n",
    "\n",
    "*You might also see a message warning you that this notebook was not authored by Google and hence might contain malicious code. You can trust Data Lab notebooks, so click __Run Anyway__. But when running other third-party notebooks, you should definitely review the code beforehand. __Do not run code you do not understand!__*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Where is the data?\n",
    "The data files used in this workshop are availalbe online on GitHub:\\\n",
    "https://github.com/tuftsdatalab/pybc/tree/master/pybc-python-data-analysis/data\n",
    "\n",
    "### Working with Files in Google Colab\n",
    "\n",
    "When using **Google Colab**, you have three options for working with data files:\n",
    "1. The data files must be publicly availalbe online via a direct-download URL.\n",
    "2. The data files must be uploaded to your *Google Drive*.\n",
    "3. You must temporarily upload the file to Google servers from within the notebook.\n",
    "\n",
    "Instructions on how to connect to your *Google Drive* from within **Google Colab** or upload local files: https://colab.research.google.com/notebooks/io.ipynb \n",
    "\n",
    "The files used in this notebook are publicly availalbe online. The direct-download URL for the files is:\\\n",
    "`https://github.com/tuftsdatalab/pybc/raw/master/pybc-python-data-analysis/data/[FILE]`\n",
    "\n",
    "Hence, if you are using **Google Colab**, please modify the code block below to set up your `DATA_PATH` as follows:\\\n",
    "`DATA_PATH = 'https://github.com/tuftsdatalab/pybc/raw/master/pybc-python-data-analysis/data/'`\n",
    "\n",
    "### Working with Files in Jupyter\n",
    "\n",
    "When using **Jupyter**, you can easily access local files on your computer. However, you can also easily access files online via their direct-download URL.\n",
    "\n",
    "Hence, if you are using **Jupyter** to run this notebook, you have mulitple options to access the data:\n",
    "- If you downloaded **only** the notebook, you can use the direct-download URL to access the data just like in *Google Colab*. Follow the instructions above to set up your `DATA_PATH`.\n",
    "  \n",
    "- If you downloaded the **ZIP** file containing **both** the data and the notebook, then you will find the data files in a folder named `data`. If the folder `data` is in the same folder as your notebook, modify the code block below to set up your `DATA_PATH` as follows: `DATA_PATH = 'data/'`\n",
    "  \n",
    "- If the data files are in some other location on your computer, please modify the code block below to make `DATA_PATH` the *absolute* path to your data folder. Make sure to keep one traling `/` or `\\` character to denote this is a folder.\n",
    "  \n",
    "### Setting Up your `DATA_PATH`\n",
    " \n",
    "This notebook uses the `DATA_PATH` variable to point to the location the data files are stored at.\\\n",
    "Please modify and run the code block below to set up your `DATA_PATH` as specified in the isntructions above.\\\n",
    "*Note that renaming locally stored data files will result in errors when reading in the data.*\n",
    "\n",
    "To quickly comment/uncomment a line, select the line and press `Ctrl+/` or `âŒ˜+/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you using Google Colab, use the default DATA_PATH as specified below\n",
    "# also use this setthing if are using Jupyter but do not want to store the data locally\n",
    "DATA_PATH = 'https://github.com/tuftsdatalab/pybc/raw/master/pybc-python-data-analysis/data/'\n",
    "\n",
    "# if you downloaded the notebook AND the data files, use following DATA_PATH instead\n",
    "# this assumes that all files are in a folder \"data\" that is in the same directory as the notebook\n",
    "# DATA_PATH = 'data/'\n",
    "\n",
    "# if the data files are stored is some other location, specify tour own DATA_PATH\n",
    "# use the full path and keep one trailing '/' or `\\` character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity we are using simple string concatenation via `+` to get the full path to the data files by concatenating `DATA_PATH` and the filename. However, in practice this could *easily lead to errors* and **should be avoided**. Always use `os.path` or `pathlib` to concatenate local paths and `urllib` to concatenate URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Working with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import everything we will be using for this section\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a really **bad** excel file: [grades.xlsx](https://github.com/tuftsdatalab/pybc/raw/master/pybc-python-data-analysis/data/grades.xlsx)\\\n",
    "How to read an excel file: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into a DataFrame using Pandas\n",
    "grades = pd.read_excel(DATA_PATH + 'grades.xlsx', sheet_name = 'Exam Grades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, this table is really messy and has a lot of problems.\\\n",
    "Also, take a look at the [original excel file](https://github.com/tuftsdatalab/pybc/raw/master/pybc-python-data-analysis/data/grades.xlsx) to see what was lost in the process of reading the file with **pandas**.\n",
    "\n",
    "The column names are bothering me the most. How to fix that?\\\n",
    "This might help: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = grades.rename(str.lower, axis = 'columns')\n",
    "grades.rename(columns = {'exam 1': 'exam1', 'exam_3': 'exam3'}, inplace = True)\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, much better.\n",
    "\n",
    "Note how the `.rename` method generated a new DataFrame by default. However, by setting the `inplace` flag to `True` we can modify the original DataFrame directly. This is the case for most **pandas** methods. However, it is very easy to make mistakes, so always make sure you know wheter you are creating a **copy** or midifying the **original**.\n",
    "\n",
    "Those 'absent' and 'excused' notes are preventing us from getting our ducks in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But just how smart is **pandas** when it comes to data types? Let's look at individual elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can access a column via []\n",
    "grades['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use . but this is not reccomended\n",
    "grades.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract a column as a DataFrame, use [[]]\n",
    "grades[['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use chained indexing to look at single elements\n",
    "grades['name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a closer look at datatypes\n",
    "print(type(grades['exam3'][0]))\n",
    "print(type(grades['exam3'][1]))\n",
    "print(type(grades['exam3'][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like **pandas** can easily handle different data types in the same column. However, if we want to do any arithmetic on the columns, like calculating the average exam score, having a column with mixed data tpyes might lead to **errors** or worse, ***unexpected behaviour***. Hence, even thogh **pandas** allows it, ***you should never mix data types in columns***.\n",
    "\n",
    "****EACH COLUMN SHOULD ONLY CONTAIN ONE TYPE OF DATA****\n",
    "\n",
    "Let's try to fix that by tackling those `absent` and `excused` values.\\\n",
    "I feel that if someone missed an exam and had no excuse, they should get a zero..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['exam3'][2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oh no, a really scary warning!** What is happening?\n",
    "\n",
    "Because Python uses something called *pass-by-object-reference* and does a lot of optimization in the background, the end user (that is you) has little to no control over whether thay are referencing the **original** object or a **copy**. This **warning** is just Pandas letting us know that when using *chained indexing* to write a value, the behaviour is ***undefined***, meaning that **pandas** cannot be sure wheter you are are writing to the **original** data frame or a temporary **copy**.\n",
    "\n",
    "To learn more: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check wheter we got lucky this time\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew, this time we got lucky. However, with a differet data frame the same approach might actually write the changes to a *temporary copy* and leave the original data frame unchanged. Chained indexing is dangerous and you should avoid using it to **write** values. What should we use instead?\n",
    "\n",
    "There are a **lot** of options: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
    "\n",
    "- To write a singe value, use `.at[row, column]`\n",
    "- To write a range of values (or a single value), use `.loc[row(s), column(s)]`\n",
    "\n",
    "*Note that `.at` and `.loc` use row and column labels. The numbers 0, 1, 2, 3, and 4 that we see in front of the rows are actually row labels. By default, row labels match row indexes in pandas. However, quite often you will work with rows that have actual labels. Sometimes those labels might be numeric and resemble indexes, which leads to confusion and error. Hence, if you want to make sure you are using _indexes_, not labels, use `.iat` and `.iloc` instead.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.at[2, 'exam3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always use `at` or `loc` to directly modify elements in a DataFrame.\n",
    "\n",
    "Knowing that, let's replace the excused absence with a `NaN` value.\\\n",
    "In pandas, `NaN` is the default 'no data' value and it is ignored by pandas in calculations.\\\n",
    "`NaN` is a part of the `numpy` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.loc[3, 'exam2'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at our grade table again\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily do arithetic with columns (assuming they are all numeric).\\\n",
    "Using `[]` to refer to a non-existing column automatically creates a new column.\\\n",
    "***NEVER USE `df.column` TO CREATE A NEW COLUMN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['sum'] = grades['exam1'] + grades['exam2'] + grades['exam3'] + grades['exam4']\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the `NaN` confuses Python if we use simple arithmetic. Also, typing out the names of *all* columns in annoying. Luckily, **pandas** has a lot of built-in functions for common operations across rows or columns that automatically ingore non-numeric columns.\n",
    "\n",
    "*Note that we can also use `[]` indexing to overwrite existing columns.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['sum'] = grades.sum(axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those sums do not seem right. Let's chek the data types to troubleshoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, even though we fixed replaced the strings in the `exam2` and `exam3` columns, **pandas** still retains their original designation as an `object` column, which in this case means a column with mixed data types. Because of this **pandas** skips over this column when doing arithmetic operations.\n",
    "\n",
    "Also, fixing values like this one-by-one in a large dataset is not practical. There must be a better way to handle messy data like this...\n",
    "\n",
    "Let's start over!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what options we have for reading the file:\\\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.read_excel(DATA_PATH + 'grades.xlsx', sheet_name = 'Exam Grades', na_values = 'excused')\n",
    "grades = grades.rename(str.lower, axis = 'columns')\n",
    "grades.rename(columns = {'exam 1': 'exam1', 'exam_3': 'exam3'}, inplace = True)\n",
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better, `exam2` is now numeric. But `exam3` still contains that string that should be a zero.\\\n",
    "Let's try converting to numeric: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['exam3'] = pd.to_numeric(grades['exam3'], errors = 'coerce')\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's replace all `NaN` values in `exam3` with zero.\\\n",
    "Here's the documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['exam3'] = grades['exam3'].fillna(0)\n",
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wondeful, now every column is the type it should be. Let's calculate some stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['mean'] = grades.mean(axis = 'columns')\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `.loc` to write columns. (And it is technically the ***correct*** way of doing that.)\\\n",
    "`.loc` can also be used to write rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.loc[:, 'max'] = grades.max(axis = 'columns')\n",
    "grades.loc['mean'] = grades.mean(axis = 'rows')\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how you must use `.loc[:, column]` to access a whole column.\\\n",
    "To access a whole row, use `.loc[row]` or `.loc[row, :]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1\n",
    "Fill in the entire table so we have mean, max, and min values for all students acorss exams and all exams across students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# challenge 1 answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2\n",
    "Pandas also supports string methods. Can you find a way to split the `name` column into two columns, one for the first name and one for the last name? If needed, rename the columns to have more logical names.\n",
    "\n",
    "*Hint: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# challenge 2 answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Working with ***Real*** Data\n",
    "If you exited the notebook after completing the previous section and before starting this one, you might have to reset your `DATA_PATH` variable and re-import any packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you using Google Colab, use the default DATA_PATH as specified below\n",
    "# also use this setthing if are using Jupyter but do not want to store the data locally\n",
    "DATA_PATH = 'https://github.com/tuftsdatalab/pybc/raw/master/pybc-python-data-analysis/data/'\n",
    "\n",
    "# if you downloaded the notebook AND the data files, use following DATA_PATH instead\n",
    "# this assumes that all files are in a folder \"data\" that is in the same directory as the notebook\n",
    "# DATA_PATH = 'data/'\n",
    "\n",
    "# if the data files are stored is some other location, specify tour own DATA_PATH\n",
    "# use the full path and keep one trailing '/' or `\\` character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import everything we will be using for this section\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a dataset on avocado prices: [avocado.csv](https://github.com/tuftsdatalab/pybc/raw/master/pybc-python-data-analysis/data/avocado.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocados = pd.read_csv(DATA_PATH + 'avocado.csv')\n",
    "\n",
    "# Convert the dates to a special format for plotting and analysis\n",
    "avocados.Date = pd.to_datetime(avocados['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The head funciton lets you take a look at the first few data samples and one of the very handy features of a DataFrame\n",
    "avocados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shape function gives you the overall dimension of your DataFrame\n",
    "avocados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With pandas, you can easily slice and dice data - also known as subsetting\n",
    "# Here we extract the price data for the Boston region\n",
    "avocados_boston = avocados[avocados.region == 'Boston']\n",
    "\n",
    "# You can tell the head function how many samples to display\n",
    "avocados_boston.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot historical prices for the Boston region\n",
    "avocados_boston.plot(x='Date',y='AveragePrice',figsize=(18,8), kind='line')\n",
    "plt.ylabel(\"Avocado Price [$]\")\n",
    "plt.title(\"Avocado Prices in Boston\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In some code examples you might see the use of `%matplotlib inline` when importing `matplotlib` or right before plotting with it. This was historically required to be able to display `matplotlib` figures within the notebook. However, modern versions of Jupyter and Google Colab to this by default, so it is no longer required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make a histogram\n",
    "hist_out = plt.hist(avocados.AveragePrice)\n",
    "plt.xlabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and median prices for Boston in 2017\n",
    "mean_2017 = np.mean(avocados_boston.AveragePrice[avocados_boston.year==2017])\n",
    "median_2017 = np.median(avocados_boston.AveragePrice[avocados_boston.year==2017])\n",
    "\n",
    "print(\"In 2017, the mean price for avocados in Boston was: $\", mean_2017, \"and the median price was: $\", median_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick example of some of the plots you can do with Seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# distribution plot\n",
    "sns.distplot(avocados[\"AveragePrice\"], color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1\n",
    "Plot historical avocado prices for some other region of your your choice.\\\n",
    "Use `pd.unique()` to get a list of all the regions in the dataset.\\\n",
    "Instead of using `[]` to do boolean indexing, use `df.where()` that provides the same functionality with a simpler interface.\n",
    "\n",
    "Some helpful links:\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.where.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# challenge 1 answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2\n",
    "Is there a correlation between the average price of avocados and total volume sold?\\\n",
    "A scatterplot might help. Make one using built-in **pandas** funcitonality and one using **seaborn**.\n",
    "\n",
    "Some helpful links:\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.scatter.html\n",
    "- https://seaborn.pydata.org/generated/seaborn.scatterplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# challenge 2 answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3\n",
    "We explored avocado prices across time. But what about across space?\\\n",
    "Make a bar chart showing the average price for different regions in the year 2017.\\\n",
    "If the plot is too messy, take a random sample of ten regions.\n",
    "\n",
    "Some helpful links:\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# challenge 3 answer here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
